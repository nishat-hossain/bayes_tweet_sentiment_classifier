{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e11d90c",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes Sentiment Classification for Tweets<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3664d7d1",
   "metadata": {},
   "source": [
    "In this project we will build a sentiment analysis tool that classifies positive & negative tweets from X (Twitter previously) using the multinomial Naive Bayes algorithm. Sentiment analysis can help evaluate the performance of a product, automate customer preference reports, and predict customer behavior in planning a product launch. We'll build our sentiment analyzer using this [Kaggle Tweet dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset). Our goal is at least 80% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f02a06",
   "metadata": {},
   "source": [
    "<h3>Exploring the Data<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b56d72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 4)\n",
      "text_ID           object\n",
      "tweet_text        object\n",
      "selected_text     object\n",
      "sentiment_type    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ID</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_ID                                      tweet_text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                       my boss is bullying me...   \n",
       "\n",
       "                         selected_text sentiment_type  \n",
       "0  I`d have responded, if I were going        neutral  \n",
       "1                             Sooo SAD       negative  \n",
       "2                          bullying me       negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "twitter = pd.read_csv(\"Tweets.csv\")\n",
    "\n",
    "print(twitter.shape)\n",
    "print(twitter.dtypes)\n",
    "twitter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6a24c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.524476\n",
       "negative    0.475524\n",
       "Name: sentiment_type, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We'll only focus on positive & negative sentiment, so we'll exclude neutral\n",
    "twitter = twitter[twitter[\"sentiment_type\"]!=\"neutral\"]\n",
    "\n",
    "#Now we'll fetch the sentiment percentages\n",
    "twitter[\"sentiment_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2712cd4",
   "metadata": {},
   "source": [
    "52.4% of the tweets were positive and 47.6% are negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb76928",
   "metadata": {},
   "source": [
    "<h3>Create Training and Test Sets<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2848446b",
   "metadata": {},
   "source": [
    "Split dataset into a training and a test set. Training set will comprise 80% of the data, and the test set the remaining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff231e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13090, 4)\n",
      "(3273, 4)\n"
     ]
    }
   ],
   "source": [
    "#Randomize the data\n",
    "randomized_data = twitter.sample(frac=1, random_state=1)\n",
    "\n",
    "#Calculate the index at which the split should occur\n",
    "split_index = round(len(randomized_data)*0.8)\n",
    "\n",
    "#Split for Training & Test sets\n",
    "training_set = randomized_data[:split_index].reset_index(drop=True)\n",
    "test_set = randomized_data[split_index:].reset_index(drop=True)\n",
    "\n",
    "#Look at shape\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8799b6",
   "metadata": {},
   "source": [
    "Now we'll analyze the percentage of positive and negative tweets in the training and test sets. We expect the percentages to be close to what we have in the full dataset, where about 52.4% of the tweets were positive and 47.6% were negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7005d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.521925\n",
       "negative    0.478075\n",
       "Name: sentiment_type, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[\"sentiment_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3739cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    0.534678\n",
       "negative    0.465322\n",
       "Name: sentiment_type, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"sentiment_type\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58a9e4",
   "metadata": {},
   "source": [
    "The results look good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3ee6a",
   "metadata": {},
   "source": [
    "<h3>Clean Data<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ce693",
   "metadata": {},
   "source": [
    "To calculate all the probabilities required by the algorithm, we'll first need to perform a bit of data cleaning for our training set to bring the data into a format that will allow us to easily extract all the information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aef1ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11207    good morning  i dont think it has stopped rain...\n",
       "8868                                     becuz you braggin\n",
       "9262     woah 311 is really good the rain earlier was r...\n",
       "5823     practically my whole body burns i cant bend ov...\n",
       "2523           feeling much better  doing history research\n",
       "8637      awww  omg garbo fake playing during one of th...\n",
       "4339     finally made it to jp licks in coolidge corner...\n",
       "8900      im watching some of your videos in youtube yo...\n",
       "5976                 haha better drunken tweeting you mean\n",
       "3461                                  girl talk is awesome\n",
       "12461     really good but its definitely not a 12s so m...\n",
       "11404               i kno i kknow  sigh been on but it sux\n",
       "8909     having a great time with family big ups to my ...\n",
       "5906                                      gooooood morning\n",
       "3884      they actually use standard speaker wire betwe...\n",
       "5415      i ake it youre at work then and not lazing at...\n",
       "8379                     macbook dying switching to iphone\n",
       "3852     my parents wachting tv but it is terrible and ...\n",
       "4388                              i already miss my mohawk\n",
       "10047    want to get my hands dirty with fubumvc httpbi...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def clean(string): \n",
    "    #Remove special characters with regex\n",
    "    special_removed = re.sub(r'[^a-zA-Z0-9\\s]', '', string) \n",
    "    #Remove punctuation\n",
    "    punct_removed = special_removed.replace('\\W', ' ')\n",
    "    #Make all characters lower case\n",
    "    lower_case = punct_removed.lower()\n",
    "    return lower_case\n",
    "\n",
    "training_set[\"tweet_text\"] = training_set[\"tweet_text\"].apply(str).apply(clean)\n",
    "training_set[\"tweet_text\"].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9e99c",
   "metadata": {},
   "source": [
    "<h3> Creating a Vocabulary List<h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbae8f",
   "metadata": {},
   "source": [
    "Now that we have clean data, we'll create a list with all the unique words in our training set, that is our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a855b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [haha, its, pretty, good, theyre, making, some...\n",
      "1                [happy, mamas, day, to, all, mothers]\n",
      "2    [im, sure, youd, consider, it, if, they, offer...\n",
      "Name: tweet_text, dtype: object\n",
      "['mcphee', 'friendyou', 'aahs']\n",
      "17731\n"
     ]
    }
   ],
   "source": [
    "training_set[\"tweet_text\"] = training_set[\"tweet_text\"].str.split()\n",
    "print(training_set[\"tweet_text\"].head(3))\n",
    "\n",
    "vocabulary = []\n",
    "for tweet in training_set[\"tweet_text\"]:\n",
    "    for word in tweet:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(vocabulary[:3])\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135cb79f",
   "metadata": {},
   "source": [
    "There are 17,731 unique words in our vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54eefa",
   "metadata": {},
   "source": [
    "<h3>Final Training Set<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdea95e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcphee</th>\n",
       "      <th>friendyou</th>\n",
       "      <th>aahs</th>\n",
       "      <th>mjname</th>\n",
       "      <th>pink</th>\n",
       "      <th>pollard</th>\n",
       "      <th>backbum</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>tourdeus</th>\n",
       "      <th>defiance</th>\n",
       "      <th>...</th>\n",
       "      <th>degrees</th>\n",
       "      <th>encouragementit</th>\n",
       "      <th>jacked</th>\n",
       "      <th>alexander</th>\n",
       "      <th>rem</th>\n",
       "      <th>fusion</th>\n",
       "      <th>decorated</th>\n",
       "      <th>reals</th>\n",
       "      <th>sleepytown</th>\n",
       "      <th>genious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 17731 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcphee  friendyou  aahs  mjname  pink  pollard  backbum  wisdom  tourdeus  \\\n",
       "0       0          0     0       0     0        0        0       0         0   \n",
       "1       0          0     0       0     0        0        0       0         0   \n",
       "\n",
       "   defiance  ...  degrees  encouragementit  jacked  alexander  rem  fusion  \\\n",
       "0         0  ...        0                0       0          0    0       0   \n",
       "1         0  ...        0                0       0          0    0       0   \n",
       "\n",
       "   decorated  reals  sleepytown  genious  \n",
       "0          0      0           0        0  \n",
       "1          0      0           0        0  \n",
       "\n",
       "[2 rows x 17731 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dictionary that has an empty list the length of the entire training_set for every unique word\n",
    "word_counts_per_tweet = {}\n",
    "for unique_word in vocabulary:\n",
    "    empty_list = [0]*len(training_set[\"tweet_text\"])\n",
    "    word_counts_per_tweet[unique_word] = empty_list\n",
    "\n",
    "#fill the empty lists in word_counts_per_tweet dictionary with the word counts for each tweet in the training_set\n",
    "for index, tweet in enumerate(training_set[\"tweet_text\"]):\n",
    "    for word in tweet:\n",
    "        word_counts_per_tweet[word][index]+=1\n",
    "        \n",
    "#turn word_counts_per_tweet into a dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_tweet)\n",
    "word_counts.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "593020b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ID</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment_type</th>\n",
       "      <th>mcphee</th>\n",
       "      <th>friendyou</th>\n",
       "      <th>aahs</th>\n",
       "      <th>mjname</th>\n",
       "      <th>pink</th>\n",
       "      <th>pollard</th>\n",
       "      <th>...</th>\n",
       "      <th>degrees</th>\n",
       "      <th>encouragementit</th>\n",
       "      <th>jacked</th>\n",
       "      <th>alexander</th>\n",
       "      <th>rem</th>\n",
       "      <th>fusion</th>\n",
       "      <th>decorated</th>\n",
       "      <th>reals</th>\n",
       "      <th>sleepytown</th>\n",
       "      <th>genious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>733d30d2f7</td>\n",
       "      <td>[haha, its, pretty, good, theyre, making, some...</td>\n",
       "      <td>good</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42e9dce94a</td>\n",
       "      <td>[happy, mamas, day, to, all, mothers]</td>\n",
       "      <td>Happy</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 17735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_ID                                         tweet_text  \\\n",
       "0  733d30d2f7  [haha, its, pretty, good, theyre, making, some...   \n",
       "1  42e9dce94a              [happy, mamas, day, to, all, mothers]   \n",
       "\n",
       "  selected_text sentiment_type  mcphee  friendyou  aahs  mjname  pink  \\\n",
       "0          good       positive       0          0     0       0     0   \n",
       "1         Happy       positive       0          0     0       0     0   \n",
       "\n",
       "   pollard  ...  degrees  encouragementit  jacked  alexander  rem  fusion  \\\n",
       "0        0  ...        0                0       0          0    0       0   \n",
       "1        0  ...        0                0       0          0    0       0   \n",
       "\n",
       "   decorated  reals  sleepytown  genious  \n",
       "0          0      0           0        0  \n",
       "1          0      0           0        0  \n",
       "\n",
       "[2 rows x 17735 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_training_set = pd.concat([training_set, word_counts], axis=1)\n",
    "clean_training_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0342e178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13090, 17735)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_training_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6a61c",
   "metadata": {},
   "source": [
    "<h3>Calculate Constants<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487201b",
   "metadata": {},
   "source": [
    "Now that we're done with cleaning the training set we can create the sentiment classifier. The Naive Bayes algorithm will need to answer these probability questions to be able to classify new tweets:\n",
    "\n",
    "$$\n",
    "  P(Positive | w_1,w_2, ..., w_n) \\propto P(Positive) \\cdot \\prod_{i=1}^{n}P(w_i|Positive)\\hspace{2cm}(1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "  P(Negative | w_1,w_2, ..., w_n) \\propto P(Negative) \\cdot \\prod_{i=1}^{n}P(w_i|Negative)\\hspace{1.5cm}(2)\n",
    "$$\n",
    "\n",
    "\n",
    "Also, to calculate $P(w_{i}|Positive)$ and $P(w_{i}|Negative)$ inside the formulas above, we'll need to use these equations:\n",
    "\n",
    "$$\n",
    "  P(w_i|Positive) = \\frac{N_{w_i|Positive} + \\alpha}{N_{Positive} + \\alpha \\cdot N_{Vocabulary}}\\hspace{5.8cm}(3)\n",
    "$$\n",
    "\n",
    "$$\n",
    "  P(w_i|Negative) = \\frac{N_{w_i|Negative} + \\alpha}{N_{Negative} + \\alpha \\cdot N_{Vocabulary}}\\hspace{5.5cm}(4)\n",
    "$$\n",
    "\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new tweet. We can calculate the value of these terms once and avoid doing the computations again for every new tweet. Below, we'll use our training set to calculate:\n",
    "\n",
    "- P(Positive) and P(Negative) <br>\n",
    "- N<sub>Positive</sub>, N<sub>Negative</sub>, and N<sub>Vocabulary <br>\n",
    "\n",
    "We'll also use Laplace smoothing and set $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265263a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6832, 17735)\n",
      "(6258, 17735)\n"
     ]
    }
   ],
   "source": [
    "# Isolating positive and negative tweets first\n",
    "positive_tweets = clean_training_set[clean_training_set[\"sentiment_type\"] == \"positive\"]\n",
    "negative_tweets = clean_training_set[clean_training_set[\"sentiment_type\"] == \"negative\"]\n",
    "\n",
    "print(positive_tweets.shape)\n",
    "print(negative_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e98a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5219251336898396\n",
      "0.47807486631016044\n"
     ]
    }
   ],
   "source": [
    "# P(Positive) & P(Negative)\n",
    "p_positive = len(positive_tweets) / len(clean_training_set)\n",
    "p_negative = len(negative_tweets) / len(clean_training_set)\n",
    "\n",
    "print(p_positive)\n",
    "print(p_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f35c8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88025\n",
      "82818\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# N_Positive\n",
    "n_words_per_positive_tweet = positive_tweets[\"tweet_text\"].apply(len) #ERROR ALERT\n",
    "n_positive = n_words_per_positive_tweet.sum()\n",
    "\n",
    "# N_Negative\n",
    "n_words_per_negative_tweet = negative_tweets[\"tweet_text\"].apply(len)\n",
    "n_negative = n_words_per_negative_tweet.sum()\n",
    "\n",
    "print(n_positive)\n",
    "print(n_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b696ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17731\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "print(n_vocabulary)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0fe51",
   "metadata": {},
   "source": [
    "<h3>Calculating Parameters<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa9a48",
   "metadata": {},
   "source": [
    "Now that we have the constant terms calculated above, we can move on with calculating the parameters\n",
    "and $P(w_{i}|Positive)$ and $P(w_{i}|Negative)$. Each parameter will be a conditional probability value associated with each word in the vocabulary. The parameters are calculated using formulas (3) and (4) previously listed:\n",
    "\n",
    "$$\n",
    "  P(w_i|Positive) = \\frac{N_{w_i|Positive} + \\alpha}{N_{Positive} + \\alpha \\cdot N_{Vocabulary}}\\hspace{5.8cm}(3)\n",
    "$$\n",
    "\n",
    "$$\n",
    "  P(w_i|Negative) = \\frac{N_{w_i|Negative} + \\alpha}{N_{Negative} + \\alpha \\cdot N_{Vocabulary}}\\hspace{5.5cm}(4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2d065e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate parameters in the form of a dictionary using list comprehension:\n",
    "parameters_positive = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_negative = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Calculate parameters:\n",
    "for word in vocabulary:\n",
    "    n_word_given_positive = positive_tweets[word].sum() #positive_tweets already defined in a cell above\n",
    "    p_word_given_positive = (n_word_given_positive + alpha) / (n_positive + alpha*n_vocabulary)\n",
    "    parameters_positive[word] = p_word_given_positive\n",
    "    \n",
    "    n_word_given_negative = negative_tweets[word].sum() #negative_tweets already defined in a cell above\n",
    "    p_word_given_negative = (n_word_given_negative + alpha) / (n_negative + alpha*n_vocabulary)\n",
    "    parameters_negative[word] = p_word_given_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb11e00",
   "metadata": {},
   "source": [
    "<h3>Classifying A New Tweet<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689ff5a",
   "metadata": {},
   "source": [
    "Now that we have all our parameters calculated, we can start creating the sentiment classifier. The sentiment classifier can be understood as a function that:\n",
    "\n",
    "•Takes in as input a new tweet (w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>). <br>\n",
    "•Calculates P(Positive|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Negative|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) <br>\n",
    "•Compares the values of P(Positive|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Negative|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>). If P(Positive|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) is greater than P(Negative|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) then the tweet is classified as positive, and vice versa. If both are equal then we can ask for human input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb79b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tweet):\n",
    "\n",
    "    tweet = clean(tweet)\n",
    "    tweet = tweet.lower().split()\n",
    "    \n",
    "    p_positive_given_tweet = p_positive\n",
    "    p_negative_given_tweet = p_negative\n",
    "    \n",
    "    for word in tweet:\n",
    "        if word in parameters_positive:\n",
    "            p_positive_given_tweet*=parameters_positive[word]\n",
    "            \n",
    "        if word in parameters_negative:\n",
    "            p_negative_given_tweet*=parameters_negative[word]\n",
    "    \n",
    "    \n",
    "    if p_positive_given_tweet>p_negative_given_tweet:\n",
    "        return \"positive\"\n",
    "    elif p_negative_given_tweet>p_positive_given_tweet:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"needs human classification\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de4a4ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "test1 = classify(\"i love noodles\")\n",
    "test2 = classify(\"bad weather\")\n",
    "print(test1)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1076033a",
   "metadata": {},
   "source": [
    "Now we'll add an additional column with the predicted sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a31ed6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_ID</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment_type</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2c79fd035e</td>\n",
       "      <td>Bloody servers are down at work for at least 3...</td>\n",
       "      <td>down</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>093021fd94</td>\n",
       "      <td>i hope it doesnt rain tonight tomorrow my fam....</td>\n",
       "      <td>i hope</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eaf0dc067f</td>\n",
       "      <td>is sipping OJ in the sun in San Pedro at La So...</td>\n",
       "      <td>Yummy!!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c9100b0595</td>\n",
       "      <td>I know Buffie. I am sitting in my office inst...</td>\n",
       "      <td>bummer</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text_ID                                         tweet_text  \\\n",
       "0  2c79fd035e  Bloody servers are down at work for at least 3...   \n",
       "1  093021fd94  i hope it doesnt rain tonight tomorrow my fam....   \n",
       "2  eaf0dc067f  is sipping OJ in the sun in San Pedro at La So...   \n",
       "3  c9100b0595   I know Buffie. I am sitting in my office inst...   \n",
       "\n",
       "  selected_text sentiment_type predicted  \n",
       "0          down       negative  negative  \n",
       "1        i hope       positive  positive  \n",
       "2      Yummy!!!       positive  positive  \n",
       "3        bummer       negative  negative  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"predicted\"] = test_set[\"tweet_text\"].apply(classify)\n",
    "test_set.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c38051",
   "metadata": {},
   "source": [
    "Below we'll write a script to measure how accurate our tweet classifier is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb5320e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.21234341582647\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for row in test_set.iterrows(): #user iterrows to iterate over test_set\n",
    "    row_content = row[1] #extract row content from the (index, row content) tuple produced by iterrows\n",
    "    if row_content[\"predicted\"]==row_content[\"sentiment_type\"]:\n",
    "        correct+=1\n",
    "        \n",
    "accuracy = 100*(correct/total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080dfb7",
   "metadata": {},
   "source": [
    "The test is 85% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e1726",
   "metadata": {},
   "source": [
    "<h3>Next Steps<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a642360",
   "metadata": {},
   "source": [
    "In this project, we built a sentiment classifier for Tweets from X (previously Twitter) using the multinomial Naive Bayes algorithm. The classifier had an accuracy of 85% on the test set we used, which exceeded our 80% goal.\n",
    "\n",
    "Potential next steps to improve the classifier could include:<br>\n",
    "• Analyzing the messages that were classified incorrectly and trying to figure out why the algorithm classified them incorrectly<br>\n",
    "•Making the classifying process more complex by writing an algorithm that's sensitive to letter case, emoticons, and neutral sentiment<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
